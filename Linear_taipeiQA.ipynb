{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hBKIOK4KGWuh"
   },
   "source": [
    "# **連結google 雲端資料**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "QGjAa4WTsShr",
    "outputId": "11bf8e7e-7d78-4b87-cf1c-3dd430f4f14d"
   },
   "outputs": [],
   "source": [
    "# # 取得google drive存取權限\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "azBLSxG7Givg"
   },
   "source": [
    "# Tapiei_QA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6nW_bvaVxysN"
   },
   "outputs": [],
   "source": [
    "# with open('/content/drive/Shared drives/新手村/data/Taipei_QA_new.txt') as file:\n",
    "#   data = file.readlines()  # 以 \\n 為一個單位讀取\n",
    "with open('./Taipei_QA_new.txt') as file:\n",
    "    data = file.readlines()  # 以 \\n 為一個單位讀取\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 745
    },
    "colab_type": "code",
    "id": "SBmMl8WXGJZH",
    "outputId": "6d531cd5-0ba8-4eea-c191-a7119bdc20fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "臺北市政府文化局 2018臺北藝術節FAQ\n",
      "\n",
      "臺北市政府文化局 臺北市信義區Neo19大樓後方人行道後場使用作業通告(107/06/03-05)\n",
      "\n",
      "臺北市政府文化局 2018台北電影節FAQ\n",
      "\n",
      "臺北市政府文化局 臺灣新文化運動紀念館位置與聯絡方式\n",
      "\n",
      "臺北市政府文化局 臺灣新文化運動紀念館開館及參觀時間?\n",
      "\n",
      "臺北市政府文化局 2018臺北兒童藝術節FAQ\n",
      "\n",
      "臺北市政府文化局 藝文補助之申請時間及計畫執行時間\n",
      "\n",
      "臺北市政府文化局 新芳春茶行地點、開放時間、聯絡方式\n",
      "\n",
      "臺北市政府文化局 如何前往松山文創園區\n",
      "\n",
      "臺北市政府文化局 被指定古蹟之建築物要符合何種條件，才能辦理容積移轉？\n",
      "\n",
      "臺北市政府文化局 所有權人接獲古蹟公告後，如不服指定程序該如何處理？\n",
      "\n",
      "臺北市政府文化局 臺北市政府古蹟歷史建築紀念建築聚落建築群考古遺址史蹟及文化景觀審議會如何組成？\n",
      "\n",
      "臺北市政府文化局 如何申請「古蹟」指定、「歷史建築」登錄？「古蹟」指定、「歷史建築」登錄的程序為何？\n",
      "\n",
      "臺北市政府文化局 錢穆故居營業時間？是否須收取門票？聯絡電話？交通資訊？\n",
      "\n",
      "臺北市政府文化局 林語堂故居營業時間？是否須收取門票？聯絡電話？交通資訊？\n",
      "\n",
      "臺北市政府文化局 臺北二二八紀念館開館及參觀時間?交通方式?\n",
      "\n",
      "臺北市政府文化局 所有權人的房舍被指定為古蹟後，可以獲得什麼權益？\n",
      "\n",
      "臺北市政府文化局 施工中，如發現疑似古蹟之建築物該如何處理？\n",
      "\n",
      "臺北市政府文化局 我的家鄰近古蹟，我的權益會不會受損？\n",
      "\n",
      "臺北市政府文化局 如何解除「古蹟」或「歷史建築」之身分？\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,line in enumerate(data):\n",
    "    if i < 20:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "colab_type": "code",
    "id": "o25bGFr5HS-Z",
    "outputId": "6fa1c178-7d93-43e9-9429-4236d9c5f300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 臺北市政府文化局\n",
      "question 2018臺北藝術節FAQ\n",
      "\n",
      "label 臺北市政府文化局\n",
      "question 臺北市信義區Neo19大樓後方人行道後場使用作業通告(107/06/03-05)\n",
      "\n",
      "label 臺北市政府文化局\n",
      "question 2018台北電影節FAQ\n",
      "\n",
      "label 臺北市政府文化局\n",
      "question 臺灣新文化運動紀念館位置與聯絡方式\n",
      "\n",
      "label 臺北市政府文化局\n",
      "question 臺灣新文化運動紀念館開館及參觀時間?\n",
      "\n",
      "label 臺北市政府文化局\n",
      "question 2018臺北兒童藝術節FAQ\n",
      "\n",
      "label 臺北市政府文化局\n",
      "question 藝文補助之申請時間及計畫執行時間\n",
      "\n",
      "label 臺北市政府文化局\n",
      "question 新芳春茶行地點、開放時間、聯絡方式\n",
      "\n",
      "label 臺北市政府文化局\n",
      "question 如何前往松山文創園區\n",
      "\n",
      "label 臺北市政府文化局\n",
      "question 被指定古蹟之建築物要符合何種條件，才能辦理容積移轉？\n",
      "\n",
      "label 臺北市政府文化局\n",
      "question 所有權人接獲古蹟公告後，如不服指定程序該如何處理？\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, line in enumerate(data):\n",
    "    sp = line.strip().split(' ')\n",
    "    \n",
    "    print('label',sp[0])\n",
    "    print('question',sp[1]) \n",
    "    print()\n",
    "    if i == 10 :break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "4sKhlgk_Hq-6",
    "outputId": "ce9f5c87-9f85-4f8d-b352-dfddd781d6ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "總數 7986\n",
      "類別 149\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "label = []     \n",
    "for i, line in enumerate(data):\n",
    "    num += 1\n",
    "    sp = line.strip().split(' ')\n",
    "    if sp[0] not in label:\n",
    "        label.append(sp[0])\n",
    "print('總數',num)\n",
    "print('類別',len(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Fo52vfTITh9"
   },
   "source": [
    "# 資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9BMhtUIXIVNp",
    "outputId": "0347cc53-04ec-4c94-f69e-644f67ddc11f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018臺北藝術節FAQ 臺北市政府文化局 7986 7986\n"
     ]
    }
   ],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "for i, line in enumerate(data):\n",
    "    sp = line.strip().split(' ')\n",
    "    x.append(sp[1])     #Q\n",
    "    y.append(sp[0])     #A\n",
    "print(x[0],y[0],len(x),len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s-Wk5DvkIvOR"
   },
   "source": [
    "input 處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "colab_type": "code",
    "id": "svsCPwTzIv4Z",
    "outputId": "d521084b-13ca-465a-bbd1-427393046487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: udicOpenData in /usr/local/lib/python3.5/dist-packages (2.4)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.5/dist-packages (from udicOpenData) (1.17.4)\r\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.5/dist-packages (from udicOpenData) (3.4.5)\r\n",
      "Requirement already satisfied: jieba in /usr/local/lib/python3.5/dist-packages (from udicOpenData) (0.39)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.5/dist-packages (from nltk->udicOpenData) (1.11.0)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.526 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#使用實驗室api斷詞 https://github.com/UDICatNCHU/UdicOpenData\n",
    "!pip3 install udicOpenData\n",
    "from udicOpenData.dictionary import *\n",
    "from udicOpenData.stopwords import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "colab_type": "code",
    "id": "AFOVmUiaKQ_J",
    "outputId": "942a3e3f-ceba-4a8b-f284-d0ac0701d546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018臺北藝術節FAQ\n",
      "['臺北', '藝術節', 'FAQ']\n",
      "\n",
      "臺北市信義區Neo19大樓後方人行道後場使用作業通告(107/06/03-05)\n",
      "['臺北市', '信義區', 'Neo', '大樓', '後方', '人行道', '後場', '使用', '作業', '通告']\n",
      "\n",
      "2018台北電影節FAQ\n",
      "['台北', '電影節', 'FAQ']\n",
      "\n",
      "臺灣新文化運動紀念館位置與聯絡方式\n",
      "['臺灣', '新文化運動', '紀念館', '位置', '聯絡', '方式']\n",
      "\n",
      "臺灣新文化運動紀念館開館及參觀時間?\n",
      "['臺灣', '新文化運動', '紀念館', '開館', '參觀', '時間']\n",
      "\n",
      "2018臺北兒童藝術節FAQ\n",
      "['臺北', '兒童', '藝術節', 'FAQ']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,ele in enumerate(x):\n",
    "    print(ele)\n",
    "    sen_list = list(rmsw(ele))\n",
    "    print(sen_list)\n",
    "    print()\n",
    "    if i == 5 :break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "yCFyBcqZKX1x",
    "outputId": "d018c03b-5adc-49fa-fcf7-68ae613ea0f1"
   },
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "model = models.Word2Vec.load('./model/word2vec_wiki_zh.model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "vHBYV3mQKcc6",
    "outputId": "1f6c4aff-f386-47c7-b99b-ec544d82db86"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7986\n"
     ]
    }
   ],
   "source": [
    "#將input斷詞並轉成word2vec向量 在計算其平均\n",
    "import numpy as np\n",
    "x_vector = []\n",
    "for i,q in enumerate(x):\n",
    "    word_list = list(rmsw(q))\n",
    "    tmp=[]\n",
    "    for word in word_list:\n",
    "        try:\n",
    "            tmp.append(model[word])\n",
    "            tmp = sum(tmp)\n",
    "        except:\n",
    "            continue\n",
    "    if len(tmp) != 0:\n",
    "        x_vector.append(tmp)\n",
    "    else:\n",
    "        x_vector.append(np.zeros(400,dtype=float))\n",
    "\n",
    "# print(len(tmp),len(tmp[0]))\n",
    "# print(tmp)\n",
    "# break\n",
    "\n",
    "print(len(x_vector))\n",
    "# print(x_vector[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VgKTbH_xLsB9"
   },
   "source": [
    "label 處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Ibs5JtnvLsla",
    "outputId": "c673b5e0-aadd-4d0a-f59e-8519ad8ca47d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 100 110\n",
      "['臺北市政府文化局' '臺北市政府產業發展局科技產業服務中心' '臺北市政府社會局身心障礙者福利科']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "#將label 做 LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_Encode = le.fit_transform(y) #y為答案 就是類別\n",
    "print(y_Encode[0], y_Encode[100], y_Encode[200])\n",
    "\n",
    "#反轉回文字\n",
    "print(le.inverse_transform([y_Encode[0], y_Encode[100], y_Encode[200]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KlGwk77UNOXb"
   },
   "source": [
    "切training data 與 testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "i1nW7Ie1NP1h",
    "outputId": "ca245ecf-a695-4c81-a813-4af9cb61d799"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train數 7187  test數 799\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Sklearn-train_test_split隨機劃分訓練集和測試集 https://blog.csdn.net/CherDW/article/details/54881167\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_vector, y_Encode, test_size=0.1)\n",
    "\n",
    "print(\"train數\",len(x_train),\" test數\",len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uUUMlGZkR_Cn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# new_tensor = torch.Tensor([[0,0],[0,0]])\n",
    "# print(x_train[0][0])\n",
    "x_train_tensor=torch.FloatTensor(x_train)\n",
    "y_train_tensor=torch.LongTensor(y_train)\n",
    "x_test_tensor=torch.Tensor(x_test)\n",
    "y_test_tensor=torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9JJx14GsQqRr"
   },
   "source": [
    "# PyTorch code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d4DBaLr3SEeW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f66e10c0f60>\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as Data\n",
    "BATCH_SIZE = 50\n",
    "train_dataset = Data.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "loader = Data.DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    ")\n",
    "test_dataset = Data.TensorDataset(x_test_tensor, y_test_tensor)\n",
    "t_loader = Data.DataLoader(\n",
    "    dataset = test_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    ")\n",
    "print(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nJJgQb-3Bu9b"
   },
   "source": [
    "# 網路架構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "v8SXJS4cB0Qr",
    "outputId": "1e1466bd-4ca3-4221-f7a5-0e7fa57c18b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden): Linear(in_features=400, out_features=200, bias=True)\n",
      "  (output): Linear(in_features=200, out_features=149, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.hidden = nn.Linear(400,200)\n",
    "        self.output = torch.nn.Linear(200,149)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))  # None represents zero initial hidden state\n",
    "        \n",
    "        \n",
    "        x = F.relu(self.output(x))\n",
    "        \n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0IqDj-JetGgg"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZxHLtVeCeXK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def accuracy(logits, labels):\n",
    "    outputs = np.argmax(logits, axis=1)\n",
    "    num_correct = torch.eq(outputs, labels).sum().item()\n",
    "    return num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CEW-zscMtIqv",
    "outputId": "e36e50a9-3912-4690-8e70-0772cb402b9b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train_loss: 4.7783 train_acc: 0.0892 test_loss: 4.612 test_acc: 0.1264\n",
      "epoch: 2 train_loss: 4.4194 train_acc: 0.1564 test_loss: 4.3752 test_acc: 0.1514\n",
      "epoch: 3 train_loss: 4.1899 train_acc: 0.1894 test_loss: 4.2314 test_acc: 0.1852\n",
      "epoch: 4 train_loss: 4.0394 train_acc: 0.2244 test_loss: 4.1353 test_acc: 0.2028\n",
      "epoch: 5 train_loss: 3.9275 train_acc: 0.2427 test_loss: 4.0764 test_acc: 0.2128\n",
      "epoch: 6 train_loss: 3.8427 train_acc: 0.2573 test_loss: 4.0269 test_acc: 0.2215\n",
      "epoch: 7 train_loss: 3.7692 train_acc: 0.2727 test_loss: 3.9783 test_acc: 0.2315\n",
      "epoch: 8 train_loss: 3.7021 train_acc: 0.2794 test_loss: 3.9441 test_acc: 0.2365\n",
      "epoch: 9 train_loss: 3.6491 train_acc: 0.2869 test_loss: 3.9271 test_acc: 0.2353\n",
      "epoch: 10 train_loss: 3.6035 train_acc: 0.2921 test_loss: 3.9105 test_acc: 0.2378\n",
      "epoch: 11 train_loss: 3.5616 train_acc: 0.3005 test_loss: 3.883 test_acc: 0.2378\n",
      "epoch: 12 train_loss: 3.5238 train_acc: 0.3061 test_loss: 3.8874 test_acc: 0.2303\n",
      "epoch: 13 train_loss: 3.4956 train_acc: 0.3094 test_loss: 3.8648 test_acc: 0.2365\n",
      "epoch: 14 train_loss: 3.4668 train_acc: 0.3104 test_loss: 3.8701 test_acc: 0.2416\n",
      "epoch: 15 train_loss: 3.439 train_acc: 0.3189 test_loss: 3.8615 test_acc: 0.2428\n",
      "epoch: 16 train_loss: 3.4131 train_acc: 0.3224 test_loss: 3.8507 test_acc: 0.2453\n",
      "epoch: 17 train_loss: 3.3921 train_acc: 0.3256 test_loss: 3.8573 test_acc: 0.2441\n",
      "epoch: 18 train_loss: 3.3699 train_acc: 0.3268 test_loss: 3.8587 test_acc: 0.2466\n",
      "epoch: 19 train_loss: 3.3535 train_acc: 0.326 test_loss: 3.849 test_acc: 0.2453\n",
      "epoch: 20 train_loss: 3.3355 train_acc: 0.3313 test_loss: 3.8545 test_acc: 0.2441\n",
      "epoch: 21 train_loss: 3.3186 train_acc: 0.3328 test_loss: 3.8507 test_acc: 0.2466\n",
      "epoch: 22 train_loss: 3.3036 train_acc: 0.3352 test_loss: 3.8486 test_acc: 0.2516\n",
      "epoch: 23 train_loss: 3.2905 train_acc: 0.3327 test_loss: 3.8467 test_acc: 0.2441\n",
      "epoch: 24 train_loss: 3.2743 train_acc: 0.3378 test_loss: 3.8676 test_acc: 0.2453\n",
      "epoch: 25 train_loss: 3.2627 train_acc: 0.3367 test_loss: 3.8512 test_acc: 0.2416\n",
      "epoch: 26 train_loss: 3.2524 train_acc: 0.3376 test_loss: 3.8336 test_acc: 0.2491\n",
      "epoch: 27 train_loss: 3.2347 train_acc: 0.3395 test_loss: 3.8527 test_acc: 0.2428\n",
      "epoch: 28 train_loss: 3.2253 train_acc: 0.3381 test_loss: 3.8761 test_acc: 0.2353\n",
      "epoch: 29 train_loss: 3.2183 train_acc: 0.3382 test_loss: 3.8515 test_acc: 0.2453\n",
      "epoch: 30 train_loss: 3.2088 train_acc: 0.3406 test_loss: 3.8392 test_acc: 0.2503\n",
      "epoch: 31 train_loss: 3.1993 train_acc: 0.3374 test_loss: 3.8522 test_acc: 0.2553\n",
      "epoch: 32 train_loss: 3.1955 train_acc: 0.3423 test_loss: 3.8555 test_acc: 0.2466\n",
      "epoch: 33 train_loss: 3.1824 train_acc: 0.3452 test_loss: 3.8505 test_acc: 0.2466\n",
      "epoch: 34 train_loss: 3.1756 train_acc: 0.3447 test_loss: 3.8479 test_acc: 0.2566\n",
      "epoch: 35 train_loss: 3.1692 train_acc: 0.3456 test_loss: 3.8405 test_acc: 0.2503\n",
      "epoch: 36 train_loss: 3.1591 train_acc: 0.3455 test_loss: 3.8536 test_acc: 0.2566\n",
      "epoch: 37 train_loss: 3.156 train_acc: 0.3438 test_loss: 3.8535 test_acc: 0.2641\n",
      "epoch: 38 train_loss: 3.1462 train_acc: 0.3451 test_loss: 3.8465 test_acc: 0.2616\n",
      "epoch: 39 train_loss: 3.1389 train_acc: 0.3492 test_loss: 3.8453 test_acc: 0.2553\n",
      "epoch: 40 train_loss: 3.1367 train_acc: 0.349 test_loss: 3.8586 test_acc: 0.2566\n",
      "epoch: 41 train_loss: 3.1277 train_acc: 0.3513 test_loss: 3.8518 test_acc: 0.2591\n",
      "epoch: 42 train_loss: 3.1213 train_acc: 0.3501 test_loss: 3.8411 test_acc: 0.2578\n",
      "epoch: 43 train_loss: 3.118 train_acc: 0.3533 test_loss: 3.86 test_acc: 0.2553\n",
      "epoch: 44 train_loss: 3.1117 train_acc: 0.3509 test_loss: 3.8699 test_acc: 0.2603\n",
      "epoch: 45 train_loss: 3.1091 train_acc: 0.3533 test_loss: 3.8667 test_acc: 0.2566\n",
      "epoch: 46 train_loss: 3.1029 train_acc: 0.3492 test_loss: 3.847 test_acc: 0.2616\n",
      "epoch: 47 train_loss: 3.0975 train_acc: 0.3565 test_loss: 3.8446 test_acc: 0.2641\n",
      "epoch: 48 train_loss: 3.0935 train_acc: 0.3529 test_loss: 3.8381 test_acc: 0.2603\n",
      "epoch: 49 train_loss: 3.0904 train_acc: 0.3536 test_loss: 3.866 test_acc: 0.2478\n",
      "epoch: 50 train_loss: 3.0834 train_acc: 0.3587 test_loss: 3.8694 test_acc: 0.2728\n",
      "epoch: 51 train_loss: 3.0812 train_acc: 0.3547 test_loss: 3.8615 test_acc: 0.2628\n",
      "epoch: 52 train_loss: 3.0773 train_acc: 0.3563 test_loss: 3.8636 test_acc: 0.2541\n",
      "epoch: 53 train_loss: 3.0718 train_acc: 0.3569 test_loss: 3.8586 test_acc: 0.2628\n",
      "epoch: 54 train_loss: 3.068 train_acc: 0.3556 test_loss: 3.8557 test_acc: 0.2678\n",
      "epoch: 55 train_loss: 3.0638 train_acc: 0.3605 test_loss: 3.871 test_acc: 0.2603\n",
      "epoch: 56 train_loss: 3.061 train_acc: 0.3604 test_loss: 3.8551 test_acc: 0.2591\n",
      "epoch: 57 train_loss: 3.0577 train_acc: 0.3608 test_loss: 3.8662 test_acc: 0.2628\n",
      "epoch: 58 train_loss: 3.0509 train_acc: 0.3612 test_loss: 3.8512 test_acc: 0.2591\n",
      "epoch: 59 train_loss: 3.0494 train_acc: 0.3616 test_loss: 3.8714 test_acc: 0.2503\n",
      "epoch: 60 train_loss: 3.0485 train_acc: 0.3595 test_loss: 3.88 test_acc: 0.2553\n",
      "epoch: 61 train_loss: 3.0422 train_acc: 0.363 test_loss: 3.8702 test_acc: 0.2591\n",
      "epoch: 62 train_loss: 3.0419 train_acc: 0.3648 test_loss: 3.8694 test_acc: 0.2503\n",
      "epoch: 63 train_loss: 3.036 train_acc: 0.3609 test_loss: 3.8591 test_acc: 0.2603\n",
      "epoch: 64 train_loss: 3.0339 train_acc: 0.363 test_loss: 3.8652 test_acc: 0.2616\n",
      "epoch: 65 train_loss: 3.0309 train_acc: 0.3651 test_loss: 3.8749 test_acc: 0.2616\n",
      "epoch: 66 train_loss: 3.0314 train_acc: 0.3604 test_loss: 3.8587 test_acc: 0.2666\n",
      "epoch: 67 train_loss: 3.0277 train_acc: 0.3633 test_loss: 3.8724 test_acc: 0.2566\n",
      "epoch: 68 train_loss: 3.0233 train_acc: 0.3625 test_loss: 3.8621 test_acc: 0.2603\n",
      "epoch: 69 train_loss: 3.0202 train_acc: 0.3659 test_loss: 3.8682 test_acc: 0.2603\n",
      "epoch: 70 train_loss: 3.0187 train_acc: 0.3616 test_loss: 3.8679 test_acc: 0.2516\n",
      "epoch: 71 train_loss: 3.013 train_acc: 0.3675 test_loss: 3.8655 test_acc: 0.2628\n",
      "epoch: 72 train_loss: 3.015 train_acc: 0.3657 test_loss: 3.87 test_acc: 0.2641\n",
      "epoch: 73 train_loss: 3.0114 train_acc: 0.3634 test_loss: 3.8774 test_acc: 0.2641\n",
      "epoch: 74 train_loss: 3.0076 train_acc: 0.3665 test_loss: 3.865 test_acc: 0.2653\n",
      "epoch: 75 train_loss: 3.0064 train_acc: 0.3637 test_loss: 3.8656 test_acc: 0.2666\n",
      "epoch: 76 train_loss: 3.005 train_acc: 0.3644 test_loss: 3.8717 test_acc: 0.2628\n",
      "epoch: 77 train_loss: 3.002 train_acc: 0.3634 test_loss: 3.8746 test_acc: 0.2603\n",
      "epoch: 78 train_loss: 2.9971 train_acc: 0.3655 test_loss: 3.8913 test_acc: 0.2591\n",
      "epoch: 79 train_loss: 2.9994 train_acc: 0.3643 test_loss: 3.8801 test_acc: 0.2666\n",
      "epoch: 80 train_loss: 2.9987 train_acc: 0.3639 test_loss: 3.8869 test_acc: 0.2628\n",
      "epoch: 81 train_loss: 2.9936 train_acc: 0.3657 test_loss: 3.8826 test_acc: 0.2641\n",
      "epoch: 82 train_loss: 2.9929 train_acc: 0.3665 test_loss: 3.8659 test_acc: 0.2641\n",
      "epoch: 83 train_loss: 2.9908 train_acc: 0.3651 test_loss: 3.8781 test_acc: 0.2653\n",
      "epoch: 84 train_loss: 2.9874 train_acc: 0.3664 test_loss: 3.8734 test_acc: 0.2678\n",
      "epoch: 85 train_loss: 2.9842 train_acc: 0.3669 test_loss: 3.8765 test_acc: 0.2703\n",
      "epoch: 86 train_loss: 2.9831 train_acc: 0.3673 test_loss: 3.8906 test_acc: 0.2578\n",
      "epoch: 87 train_loss: 2.983 train_acc: 0.3671 test_loss: 3.8925 test_acc: 0.2541\n",
      "epoch: 88 train_loss: 2.9793 train_acc: 0.3677 test_loss: 3.8801 test_acc: 0.2641\n",
      "epoch: 89 train_loss: 2.977 train_acc: 0.3698 test_loss: 3.8792 test_acc: 0.2653\n",
      "epoch: 90 train_loss: 2.9757 train_acc: 0.3714 test_loss: 3.8808 test_acc: 0.2603\n",
      "epoch: 91 train_loss: 2.9744 train_acc: 0.3637 test_loss: 3.8851 test_acc: 0.2641\n",
      "epoch: 92 train_loss: 2.9727 train_acc: 0.3698 test_loss: 3.8896 test_acc: 0.2641\n",
      "epoch: 93 train_loss: 2.9704 train_acc: 0.3703 test_loss: 3.8972 test_acc: 0.2628\n",
      "epoch: 94 train_loss: 2.9721 train_acc: 0.3677 test_loss: 3.896 test_acc: 0.2716\n",
      "epoch: 95 train_loss: 2.9702 train_acc: 0.3652 test_loss: 3.8781 test_acc: 0.2703\n",
      "epoch: 96 train_loss: 2.9632 train_acc: 0.3716 test_loss: 3.8842 test_acc: 0.2616\n",
      "epoch: 97 train_loss: 2.9638 train_acc: 0.3689 test_loss: 3.8837 test_acc: 0.2616\n",
      "epoch: 98 train_loss: 2.9638 train_acc: 0.3712 test_loss: 3.884 test_acc: 0.2691\n",
      "epoch: 99 train_loss: 2.9618 train_acc: 0.368 test_loss: 3.892 test_acc: 0.2616\n",
      "epoch: 100 train_loss: 2.9609 train_acc: 0.3696 test_loss: 3.8852 test_acc: 0.2741\n"
     ]
    }
   ],
   "source": [
    "LR = 0.0003\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=LR)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    net.train()\n",
    "    for i, data in enumerate(loader):\n",
    "        inputs, labels = data\n",
    "        logits = net(inputs)\n",
    "        train_correct += accuracy(torch.tensor(logits),labels)\n",
    "    \n",
    "        loss = loss_func(logits, labels)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    net.eval()\n",
    "    for i, data  in enumerate(t_loader):\n",
    "        with torch.no_grad():\n",
    "            inputs, labels = data\n",
    "            logits = net(inputs)\n",
    "            loss = loss_func(logits, labels)\n",
    "        test_loss += loss.item()\n",
    "        test_correct += accuracy(logits, labels)\n",
    "\n",
    "    print(\n",
    "    'epoch:',epoch+1,\n",
    "    'train_loss:',round(train_loss/len(loader), 4),\n",
    "    'train_acc:',round(train_correct/len(train_dataset), 4),\n",
    "    'test_loss:',round(test_loss/len(t_loader), 4),\n",
    "    'test_acc:',round(test_correct/len(test_dataset), 4)    \n",
    "    )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cBRM5NFBGazL"
   },
   "source": [
    "# 網路儲存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "jyN7jBpeGOte",
    "outputId": "6f5769e4-2514-4b6c-e37d-cd6b52b87381"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4c47119a3e1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"net.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(net,\"net.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "colab_type": "code",
    "id": "ShZ-UfUnGkQx",
    "outputId": "95fbc64c-bece-45f6-f01d-9a6103879a09"
   },
   "outputs": [],
   "source": [
    "trained = torch.load(\"net.pkl\")\n",
    "while True:\n",
    "    # 存下input的向量\n",
    "    a=input(\"問題:\")\n",
    "    word_vec = list(rmsw(a))\n",
    "    print(word_vec)\n",
    "    tmp = []\n",
    "    for word in word_vec:\n",
    "        try:\n",
    "            tmp.append(model[word])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    while len(tmp)<10:\n",
    "        tmp.append(np.zeros(400,dtype=float))\n",
    "\n",
    "    tmp = tmp[:10]\n",
    "\n",
    "    # 丟入網路\n",
    "    tmp_tensor = torch.Tensor([tmp])\n",
    "    li = trained(tmp_tensor).tolist()[0]\n",
    "    print(li)\n",
    "    class_value = li.index(max(li))\n",
    "    print(\"相關局處:\",le.inverse_transform([class_value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AzykQRCZ5yDZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l_cNOIPy5yB8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNN_taipeiQA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
